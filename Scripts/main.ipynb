{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target    276\n",
      "a           3\n",
      "b           0\n",
      "c           0\n",
      "d         635\n",
      "e           0\n",
      "f           0\n",
      "g           0\n",
      "h          38\n",
      "i         109\n",
      "j         605\n",
      "k           0\n",
      "l           0\n",
      "m         418\n",
      "n         184\n",
      "o         188\n",
      "p          74\n",
      "q         187\n",
      "r           0\n",
      "s           0\n",
      "t          86\n",
      "u         117\n",
      "v          80\n",
      "w         117\n",
      "x         799\n",
      "y           0\n",
      "z         598\n",
      "{          74\n",
      "dtype: int64\n",
      "Accuracy: 0.8\n",
      "Accuracy: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hajip\\Desktop\\humber\\BINF AI\\Data-Wrangling\\Scripts\\data_preprocessor.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_imputed[colname].fillna(data_imputed[colname].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import data_preprocessor as dp\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the dataset\n",
    "messy_data = pd.read_csv('../Data/messy_data.csv')\n",
    "# messy_data.head()\n",
    "# messy_data.info()\n",
    "clean_data = messy_data.copy()\n",
    "\n",
    "#check how many missing data in each column\n",
    "missing_data = clean_data.isnull().sum()\n",
    "print(missing_data)\n",
    "\n",
    "# -------------------- This step is commented out,to observe data preprocessor pergormance -------------\n",
    "# ideally would remove samples that have missing values, however in this example we remain with very less remaining\n",
    "# removing features with high missing values\n",
    "# clean_data= clean_data.drop(['d', 'j', 'm', 'x', 'z'], axis=1)\n",
    "\n",
    "# 2. Preprocess the data\n",
    "clean_data = dp.impute_missing_values(data=clean_data, strategy='mean')\n",
    "clean_data = dp.remove_duplicates(clean_data)\n",
    "clean_data = dp.normalize_data(clean_data,method =\"standard\")\n",
    "clean_data = dp.remove_redundant_features(clean_data)\n",
    "\n",
    "# 3. Save the cleaned dataset\n",
    "clean_data.to_csv('../Data/clean_data.csv', index=False)\n",
    "\n",
    "final_data= clean_data.copy()\n",
    "# 4. Train and evaluate the model\n",
    "dp.simple_model(messy_data)\n",
    "dp.simple_model(final_data)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
